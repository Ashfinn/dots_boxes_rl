<!DOCTYPE html>
<html>
<head>
<title>readme.md</title>
<meta http-equiv="Content-type" content="text/html;charset=UTF-8">

<style>
/* https://github.com/microsoft/vscode/blob/master/extensions/markdown-language-features/media/markdown.css */
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

body {
	font-family: var(--vscode-markdown-font-family, -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif);
	font-size: var(--vscode-markdown-font-size, 14px);
	padding: 0 26px;
	line-height: var(--vscode-markdown-line-height, 22px);
	word-wrap: break-word;
}

#code-csp-warning {
	position: fixed;
	top: 0;
	right: 0;
	color: white;
	margin: 16px;
	text-align: center;
	font-size: 12px;
	font-family: sans-serif;
	background-color:#444444;
	cursor: pointer;
	padding: 6px;
	box-shadow: 1px 1px 1px rgba(0,0,0,.25);
}

#code-csp-warning:hover {
	text-decoration: none;
	background-color:#007acc;
	box-shadow: 2px 2px 2px rgba(0,0,0,.25);
}

body.scrollBeyondLastLine {
	margin-bottom: calc(100vh - 22px);
}

body.showEditorSelection .code-line {
	position: relative;
}

body.showEditorSelection .code-active-line:before,
body.showEditorSelection .code-line:hover:before {
	content: "";
	display: block;
	position: absolute;
	top: 0;
	left: -12px;
	height: 100%;
}

body.showEditorSelection li.code-active-line:before,
body.showEditorSelection li.code-line:hover:before {
	left: -30px;
}

.vscode-light.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(0, 0, 0, 0.15);
}

.vscode-light.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(0, 0, 0, 0.40);
}

.vscode-light.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-dark.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 255, 255, 0.4);
}

.vscode-dark.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 255, 255, 0.60);
}

.vscode-dark.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-high-contrast.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 160, 0, 0.7);
}

.vscode-high-contrast.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 160, 0, 1);
}

.vscode-high-contrast.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

img {
	max-width: 100%;
	max-height: 100%;
}

a {
	text-decoration: none;
}

a:hover {
	text-decoration: underline;
}

a:focus,
input:focus,
select:focus,
textarea:focus {
	outline: 1px solid -webkit-focus-ring-color;
	outline-offset: -1px;
}

hr {
	border: 0;
	height: 2px;
	border-bottom: 2px solid;
}

h1 {
	padding-bottom: 0.3em;
	line-height: 1.2;
	border-bottom-width: 1px;
	border-bottom-style: solid;
}

h1, h2, h3 {
	font-weight: normal;
}

table {
	border-collapse: collapse;
}

table > thead > tr > th {
	text-align: left;
	border-bottom: 1px solid;
}

table > thead > tr > th,
table > thead > tr > td,
table > tbody > tr > th,
table > tbody > tr > td {
	padding: 5px 10px;
}

table > tbody > tr + tr > td {
	border-top: 1px solid;
}

blockquote {
	margin: 0 7px 0 5px;
	padding: 0 16px 0 10px;
	border-left-width: 5px;
	border-left-style: solid;
}

code {
	font-family: Menlo, Monaco, Consolas, "Droid Sans Mono", "Courier New", monospace, "Droid Sans Fallback";
	font-size: 1em;
	line-height: 1.357em;
}

body.wordWrap pre {
	white-space: pre-wrap;
}

pre:not(.hljs),
pre.hljs code > div {
	padding: 16px;
	border-radius: 3px;
	overflow: auto;
}

pre code {
	color: var(--vscode-editor-foreground);
	tab-size: 4;
}

/** Theming */

.vscode-light pre {
	background-color: rgba(220, 220, 220, 0.4);
}

.vscode-dark pre {
	background-color: rgba(10, 10, 10, 0.4);
}

.vscode-high-contrast pre {
	background-color: rgb(0, 0, 0);
}

.vscode-high-contrast h1 {
	border-color: rgb(0, 0, 0);
}

.vscode-light table > thead > tr > th {
	border-color: rgba(0, 0, 0, 0.69);
}

.vscode-dark table > thead > tr > th {
	border-color: rgba(255, 255, 255, 0.69);
}

.vscode-light h1,
.vscode-light hr,
.vscode-light table > tbody > tr + tr > td {
	border-color: rgba(0, 0, 0, 0.18);
}

.vscode-dark h1,
.vscode-dark hr,
.vscode-dark table > tbody > tr + tr > td {
	border-color: rgba(255, 255, 255, 0.18);
}

</style>

<style>
/* Tomorrow Theme */
/* http://jmblog.github.com/color-themes-for-google-code-highlightjs */
/* Original theme - https://github.com/chriskempson/tomorrow-theme */

/* Tomorrow Comment */
.hljs-comment,
.hljs-quote {
	color: #8e908c;
}

/* Tomorrow Red */
.hljs-variable,
.hljs-template-variable,
.hljs-tag,
.hljs-name,
.hljs-selector-id,
.hljs-selector-class,
.hljs-regexp,
.hljs-deletion {
	color: #c82829;
}

/* Tomorrow Orange */
.hljs-number,
.hljs-built_in,
.hljs-builtin-name,
.hljs-literal,
.hljs-type,
.hljs-params,
.hljs-meta,
.hljs-link {
	color: #f5871f;
}

/* Tomorrow Yellow */
.hljs-attribute {
	color: #eab700;
}

/* Tomorrow Green */
.hljs-string,
.hljs-symbol,
.hljs-bullet,
.hljs-addition {
	color: #718c00;
}

/* Tomorrow Blue */
.hljs-title,
.hljs-section {
	color: #4271ae;
}

/* Tomorrow Purple */
.hljs-keyword,
.hljs-selector-tag {
	color: #8959a8;
}

.hljs {
	display: block;
	overflow-x: auto;
	color: #4d4d4c;
	padding: 0.5em;
}

.hljs-emphasis {
	font-style: italic;
}

.hljs-strong {
	font-weight: bold;
}
</style>

<style>
/*
 * Markdown PDF CSS
 */

 body {
	font-family: -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif, "Meiryo";
	padding: 0 12px;
}

pre {
	background-color: #f8f8f8;
	border: 1px solid #cccccc;
	border-radius: 3px;
	overflow-x: auto;
	white-space: pre-wrap;
	overflow-wrap: break-word;
}

pre:not(.hljs) {
	padding: 23px;
	line-height: 19px;
}

blockquote {
	background: rgba(127, 127, 127, 0.1);
	border-color: rgba(0, 122, 204, 0.5);
}

.emoji {
	height: 1.4em;
}

code {
	font-size: 14px;
	line-height: 19px;
}

/* for inline code */
:not(pre):not(.hljs) > code {
	color: #C9AE75; /* Change the old color so it seems less like an error */
	font-size: inherit;
}

/* Page Break : use <div class="page"/> to insert page break
-------------------------------------------------------- */
.page {
	page-break-after: always;
}

</style>

<script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
</head>
<body>
  <script>
    mermaid.initialize({
      startOnLoad: true,
      theme: document.body.classList.contains('vscode-dark') || document.body.classList.contains('vscode-high-contrast')
          ? 'dark'
          : 'default'
    });
  </script>
<p>Systematic Analysis of Scalable RL for Dots and Boxes</p>
<h2 id="project-overview">Project Overview</h2>
<p><strong>Title</strong>: &quot;Systematic Analysis of Scalable Reinforcement Learning for Dots and Boxes: From 3x3 to Large Boards&quot;
<strong>Research Gap</strong>: Existing work on larger boards is fragmented, lacks systematic comparison, and ignores computational efficiency
<strong>Your Contribution</strong>: First comprehensive, systematic study of RL scalability with CPU-efficiency focus</p>
<h2 id="research-questions">Research Questions</h2>
<h3 id="primary-research-questions">Primary Research Questions:</h3>
<ol>
<li><strong>Scalability</strong>: How do different RL algorithms perform as board size increases from 3x3 to 6x6+?</li>
<li><strong>Efficiency</strong>: Which RL methods are most computationally efficient for larger boards on CPU-only systems?</li>
<li><strong>Comparative Analysis</strong>: What are the relative strengths/weaknesses of different RL approaches across board sizes?</li>
</ol>
<h3 id="secondary-research-questions">Secondary Research Questions:</h3>
<ol>
<li><strong>Breaking Points</strong>: At what board size does each algorithm start failing?</li>
<li><strong>State Representation</strong>: How does state encoding affect scalability?</li>
<li><strong>Training Efficiency</strong>: Which methods require least training time for acceptable performance?</li>
<li><strong>Human-Level Performance</strong>: Can we achieve human-level play on larger boards efficiently?</li>
</ol>
<h2 id="literature-foundation--baselines">Literature Foundation &amp; Baselines</h2>
<h3 id="existing-work-to-build-on">Existing Work to Build On:</h3>
<ul>
<li><strong>3x3 Baselines</strong>: Pandey (2022), da Costa (2022), BoxesZero (2025)</li>
<li><strong>Larger Board Attempts</strong>: Miller et al. (6x6), Deakos (5x5), ChantalMP (12x12)</li>
<li><strong>Implementations</strong>: Multiple GitHub projects with varying approaches</li>
</ul>
<h3 id="your-systematic-approach">Your Systematic Approach:</h3>
<ul>
<li><strong>Reproduce key results</strong> from existing 3x3 work</li>
<li><strong>Systematically extend</strong> to 4x4, 5x5, 6x6 boards</li>
<li><strong>Compare methods</strong> that others tested individually</li>
<li><strong>Add CPU-efficiency analysis</strong> (novel contribution)</li>
</ul>
<h2 id="methodology-framework">Methodology Framework</h2>
<h3 id="board-sizes-for-testing">Board Sizes for Testing:</h3>
<ul>
<li><strong>3x3</strong>: Baseline comparison with existing work</li>
<li><strong>4x4</strong>: First scaling step</li>
<li><strong>5x5</strong>: Medium complexity (matches Deakos)</li>
<li><strong>6x6</strong>: High complexity (matches Miller et al.)</li>
<li><strong>Larger if feasible</strong>: Push boundaries of CPU capabilities</li>
</ul>
<h3 id="rl-algorithms-to-compare">RL Algorithms to Compare:</h3>
<ol>
<li>
<p><strong>Classical Methods</strong>:</p>
<ul>
<li>Q-Learning (tabular for small boards)</li>
<li>Deep Q-Network (DQN)</li>
<li>Policy Gradient (PPO/A2C)</li>
</ul>
</li>
<li>
<p><strong>Advanced Methods</strong>:</p>
<ul>
<li>AlphaZero-style (MCTS + NN)</li>
<li>Actor-Critic variants</li>
<li>N-Tuple networks (from MarkusThill)</li>
</ul>
</li>
<li>
<p><strong>Hybrid/Novel Approaches</strong>:</p>
<ul>
<li>Rule-based + RL combinations</li>
<li>Transfer learning across board sizes</li>
<li>CPU-optimized variants</li>
</ul>
</li>
</ol>
<h3 id="state-representations-to-test">State Representations to Test:</h3>
<ul>
<li><strong>Binary grids</strong>: Simple edge representation</li>
<li><strong>Structured features</strong>: Chains, boxes, strategic features</li>
<li><strong>Convolutional</strong>: 2D spatial representation</li>
<li><strong>Graph-based</strong>: Explicit game structure</li>
</ul>
<h3 id="evaluation-metrics">Evaluation Metrics:</h3>
<ul>
<li><strong>Performance</strong>: Win rate vs. baselines (random, heuristic, human)</li>
<li><strong>Efficiency</strong>: Training time, memory usage, inference speed</li>
<li><strong>Scalability</strong>: How metrics degrade with board size</li>
<li><strong>Robustness</strong>: Performance across different opponents</li>
</ul>
<h2 id="experimental-design">Experimental Design</h2>
<h3 id="phase-1-foundation--reproduction">Phase 1: Foundation &amp; Reproduction</h3>
<p><strong>Goal</strong>: Establish solid baselines and reproduce key existing results</p>
<p><strong>Tasks</strong>:</p>
<ul>
<li>Implement/adapt existing 3x3 algorithms</li>
<li>Reproduce key results from literature</li>
<li>Establish evaluation protocols</li>
<li>Create systematic testing framework</li>
</ul>
<p><strong>Deliverables</strong>:</p>
<ul>
<li>Working implementations of 3-4 RL algorithms</li>
<li>Validated results on 3x3 boards</li>
<li>Standardized evaluation pipeline</li>
</ul>
<h3 id="phase-2-systematic-scaling-analysis">Phase 2: Systematic Scaling Analysis</h3>
<p><strong>Goal</strong>: Comprehensive comparison across board sizes</p>
<p><strong>Experimental Matrix</strong>:</p>
<pre class="hljs"><code><div>Algorithm × Board Size × State Representation × Evaluation Metric
</div></code></pre>
<p><strong>Key Experiments</strong>:</p>
<ul>
<li><strong>Algorithm Comparison</strong>: Same setup, different algorithms</li>
<li><strong>Scaling Analysis</strong>: Same algorithm, different board sizes</li>
<li><strong>Representation Impact</strong>: Same algorithm, different state encodings</li>
<li><strong>Efficiency Analysis</strong>: Training time vs. performance trade-offs</li>
</ul>
<p><strong>Statistical Rigor</strong>:</p>
<ul>
<li>Multiple random seeds for each experiment</li>
<li>Proper significance testing</li>
<li>Confidence intervals for all results</li>
<li>Reproducibility documentation</li>
</ul>
<h3 id="phase-3-cpu-efficiency-focus">Phase 3: CPU-Efficiency Focus</h3>
<p><strong>Goal</strong>: Novel contribution focused on computational constraints</p>
<p><strong>Efficiency Experiments</strong>:</p>
<ul>
<li><strong>Training Efficiency</strong>: Time to reach acceptable performance</li>
<li><strong>Memory Usage</strong>: RAM requirements across board sizes</li>
<li><strong>Inference Speed</strong>: Decision time during play</li>
<li><strong>Scalability Limits</strong>: Maximum feasible board size per method</li>
</ul>
<p><strong>CPU-Optimized Variants</strong>:</p>
<ul>
<li>Simplified neural network architectures</li>
<li>Efficient state representations</li>
<li>Approximate methods for large boards</li>
<li>Hybrid approaches combining fast heuristics with RL</li>
</ul>
<h3 id="phase-4-advanced-analysis--novel-contributions">Phase 4: Advanced Analysis &amp; Novel Contributions</h3>
<p><strong>Goal</strong>: Push beyond existing work with new insights</p>
<p><strong>Advanced Experiments</strong>:</p>
<ul>
<li><strong>Transfer Learning</strong>: Train on small boards, test on large</li>
<li><strong>Curriculum Learning</strong>: Progressive board size training</li>
<li><strong>Multi-Agent Analysis</strong>: Self-play vs. diverse opponents</li>
<li><strong>Theoretical Analysis</strong>: Complexity bounds, convergence analysis</li>
</ul>
<p><strong>Novel Algorithmic Contributions</strong>:</p>
<ul>
<li>CPU-efficient variants of existing methods</li>
<li>Hybrid rule-based + RL approaches</li>
<li>Board-size adaptive algorithms</li>
<li>Computational budget allocation strategies</li>
</ul>
<h2 id="expected-contributions">Expected Contributions</h2>
<h3 id="primary-contributions">Primary Contributions:</h3>
<ol>
<li><strong>Systematic Scalability Analysis</strong>: First comprehensive study of RL scaling in Dots and Boxes</li>
<li><strong>CPU-Efficiency Focus</strong>: Novel analysis of computational constraints in game RL</li>
<li><strong>Comparative Methodology</strong>: Standardized evaluation framework for future research</li>
<li><strong>Practical Insights</strong>: Clear guidance on which methods work best for different scenarios</li>
</ol>
<h3 id="secondary-contributions">Secondary Contributions:</h3>
<ol>
<li><strong>Algorithmic Improvements</strong>: CPU-optimized variants of existing methods</li>
<li><strong>Theoretical Insights</strong>: Understanding of why certain methods scale better</li>
<li><strong>Reproducible Research</strong>: Open-source implementations and datasets</li>
<li><strong>Benchmark Establishment</strong>: Standard evaluation protocols for larger boards</li>
</ol>
<h2 id="target-conferences--positioning">Target Conferences &amp; Positioning</h2>
<h3 id="primary-targets">Primary Targets:</h3>
<ul>
<li><strong>AAMAS</strong>: Multi-agent systems, game theory focus</li>
<li><strong>IJCAI</strong>: AI applications, systematic studies</li>
<li><strong>CoG</strong>: Conference on Games (specialized venue)</li>
</ul>
<h3 id="secondary-targets">Secondary Targets:</h3>
<ul>
<li><strong>AAAI</strong>: General AI, practical applications</li>
<li><strong>AIIDE</strong>: Interactive entertainment, games</li>
<li><strong>Various workshops</strong>: At NeurIPS, ICML, etc.</li>
</ul>
<h3 id="paper-positioning">Paper Positioning:</h3>
<ul>
<li><strong>Systematic study</strong> (not just novel algorithm)</li>
<li><strong>Practical focus</strong> (CPU efficiency, scalability)</li>
<li><strong>Reproducible research</strong> (open source, clear methodology)</li>
<li><strong>Bridging theory and practice</strong> (academic rigor + practical constraints)</li>
</ul>
<h2 id="technical-implementation-plan">Technical Implementation Plan</h2>
<h3 id="development-environment">Development Environment:</h3>
<ul>
<li><strong>Python 3.8+</strong> with standard ML libraries</li>
<li><strong>PyTorch</strong> for deep learning (CPU optimized)</li>
<li><strong>OpenAI Gym</strong> interface for environments</li>
<li><strong>Weights &amp; Biases</strong> for experiment tracking</li>
<li><strong>Git + GitHub</strong> for version control</li>
</ul>
<h3 id="code-structure">Code Structure:</h3>
<pre class="hljs"><code><div>dots_boxes_rl/
├── environments/          # Game implementations
├── agents/               # RL algorithm implementations
├── experiments/          # Systematic experiment scripts
├── analysis/            # Result analysis and visualization
├── baselines/           # Existing work reproduction
└── utils/               # Shared utilities
</div></code></pre>
<h3 id="reproducibility-requirements">Reproducibility Requirements:</h3>
<ul>
<li><strong>Fixed random seeds</strong> for all experiments</li>
<li><strong>Detailed logging</strong> of hyperparameters and results</li>
<li><strong>Docker containers</strong> for consistent environments</li>
<li><strong>Comprehensive documentation</strong> of all procedures</li>
<li><strong>Open-source release</strong> of all code</li>
</ul>
<h2 id="success-metrics">Success Metrics</h2>
<h3 id="technical-success">Technical Success:</h3>
<ul>
<li><strong>Reproduction</strong>: Successfully reproduce 3+ existing results</li>
<li><strong>Scaling</strong>: Demonstrate systematic scaling analysis up to 6x6</li>
<li><strong>Efficiency</strong>: Show clear computational efficiency comparisons</li>
<li><strong>Novel Insights</strong>: Identify at least 2 new algorithmic improvements</li>
</ul>
<h3 id="publication-success">Publication Success:</h3>
<ul>
<li><strong>Paper Acceptance</strong>: Target tier 2-3 conference acceptance</li>
<li><strong>Reproducibility</strong>: All results independently verifiable</li>
<li><strong>Impact</strong>: Citations from follow-up work</li>
<li><strong>Open Source</strong>: Community adoption of code/benchmarks</li>
</ul>
<h3 id="personal-success">Personal Success:</h3>
<ul>
<li><strong>Deep RL Understanding</strong>: Master multiple RL algorithms</li>
<li><strong>Research Skills</strong>: Develop systematic experimental methodology</li>
<li><strong>Technical Skills</strong>: Advanced Python/PyTorch proficiency</li>
<li><strong>Academic Writing</strong>: Produce publication-quality paper</li>
</ul>
<h2 id="risk-mitigation">Risk Mitigation</h2>
<h3 id="technical-risks">Technical Risks:</h3>
<ul>
<li><strong>Computational Limits</strong>: Focus on CPU-efficient methods, smaller boards if needed</li>
<li><strong>Implementation Bugs</strong>: Extensive testing, reproduce known results first</li>
<li><strong>Experimental Complexity</strong>: Start simple, add complexity gradually</li>
</ul>
<h3 id="research-risks">Research Risks:</h3>
<ul>
<li><strong>Limited Novelty</strong>: CPU-efficiency angle provides clear differentiation</li>
<li><strong>Negative Results</strong>: Systematic failure analysis is still valuable</li>
<li><strong>Scope Creep</strong>: Well-defined research questions with clear boundaries</li>
</ul>
<h3 id="timeline-risks">Timeline Risks:</h3>
<ul>
<li><strong>Reproduction Takes Too Long</strong>: Use existing implementations where possible</li>
<li><strong>Experiments Don't Converge</strong>: Have backup simpler algorithms</li>
<li><strong>Writing Delays</strong>: Start writing early, parallel to experiments</li>
</ul>
<h2 id="resources--tools">Resources &amp; Tools</h2>
<h3 id="computational-resources">Computational Resources:</h3>
<ul>
<li><strong>Your CPU</strong>: AMD 5600G (sufficient for this project)</li>
<li><strong>Cloud Computing</strong>: Consider Google Colab/Kaggle for large experiments</li>
<li><strong>Storage</strong>: Local + cloud backup for all experimental data</li>
</ul>
<h3 id="software-tools">Software Tools:</h3>
<ul>
<li><strong>Development</strong>: VS Code, Jupyter notebooks</li>
<li><strong>Experiment Tracking</strong>: Weights &amp; Biases, TensorBoard</li>
<li><strong>Visualization</strong>: Matplotlib, Seaborn, Plotly</li>
<li><strong>Writing</strong>: LaTeX, Overleaf</li>
<li><strong>Reference Management</strong>: Zotero, Mendeley</li>
</ul>
<h3 id="learning-resources">Learning Resources:</h3>
<ul>
<li><strong>RL Textbooks</strong>: Sutton &amp; Barto, Bertsekas</li>
<li><strong>Online Courses</strong>: Spinning Up, CS234 Stanford</li>
<li><strong>Paper Repositories</strong>: ArXiv, Google Scholar alerts</li>
<li><strong>Code Examples</strong>: GitHub repositories, research reproductions</li>
</ul>
<h2 id="expected-outcomes">Expected Outcomes</h2>
<h3 id="academic-impact">Academic Impact:</h3>
<ul>
<li><strong>Systematic Understanding</strong>: Clear picture of RL scalability in Dots and Boxes</li>
<li><strong>Methodological Contribution</strong>: Framework for systematic game RL evaluation</li>
<li><strong>Practical Insights</strong>: Guidance for practitioners with limited computational resources</li>
<li><strong>Future Research</strong>: Foundation for more advanced work in this area</li>
</ul>
<h3 id="technical-outcomes">Technical Outcomes:</h3>
<ul>
<li><strong>Open Source Framework</strong>: Reusable code for Dots and Boxes RL research</li>
<li><strong>Benchmark Suite</strong>: Standard evaluation protocols and baselines</li>
<li><strong>Algorithmic Improvements</strong>: CPU-efficient variants of existing methods</li>
<li><strong>Empirical Database</strong>: Comprehensive results across methods and board sizes</li>
</ul>
<h3 id="personal-development">Personal Development:</h3>
<ul>
<li><strong>Research Expertise</strong>: Deep understanding of RL and systematic experimentation</li>
<li><strong>Technical Skills</strong>: Advanced ML engineering and experimental design</li>
<li><strong>Academic Writing</strong>: Publication-quality research communication</li>
<li><strong>Domain Knowledge</strong>: Expertise in game AI and computational efficiency</li>
</ul>
<p>This research plan positions you to make meaningful contributions to an active research area while building on existing work systematically. The CPU-efficiency focus provides a clear novel angle that distinguishes your work from existing fragmented efforts.</p>

</body>
</html>
